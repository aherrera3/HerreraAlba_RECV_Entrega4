{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HerreraAlbaAngelica_RECV_Entrega4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdAi5ZX0J_lY"
      },
      "source": [
        "# ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nrDmsolTAqRM",
        "outputId": "98886067-70d5-40ed-92da-bb0413f2e8d3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('MLP_regresion.csv')\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-10.00000</td>\n",
              "      <td>0.929135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9.97998</td>\n",
              "      <td>0.634406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9.95996</td>\n",
              "      <td>0.946741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9.93994</td>\n",
              "      <td>0.578634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9.91992</td>\n",
              "      <td>0.721276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          X         Y\n",
              "0 -10.00000  0.929135\n",
              "1  -9.97998  0.634406\n",
              "2  -9.95996  0.946741\n",
              "3  -9.93994  0.578634\n",
              "4  -9.91992  0.721276"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgI_cxnHBMNf"
      },
      "source": [
        "X = np.array(data['X'])   #feature\n",
        "Y = np.array(data['Y'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPV7j2x2CQZ0"
      },
      "source": [
        "# Escalando los datos\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "r3mMnrjCKsA5",
        "outputId": "d3929408-9161-44cd-d094-a06c9db28e15"
      },
      "source": [
        "# le aplico el standard scaler a X\n",
        "X_scaled = scaler.fit_transform([X])\n",
        "\n",
        "# distribucion de feature\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(X_scaled)\n",
        "plt.xlim(0,0.1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJj0_B-lORR-",
        "outputId": "d6c39d05-ef53-41f0-87f3-1345e7a0aa12"
      },
      "source": [
        "import numpy as np\n",
        "np.shape(X_scaled)  # vector fila"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYatgcoCOoG8",
        "outputId": "e8f06694-e20f-45dd-cec7-582d3ec715ab"
      },
      "source": [
        "# convierto X_scaled a vector columna\n",
        "X_scaled = X_scaled.T\n",
        "np.shape(X_scaled)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-dR4wZSKsFX"
      },
      "source": [
        "# dividiendo entre training y test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.6, random_state=40)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIjvzR7mKsJp",
        "outputId": "4cb851ee-9275-4250-cd96-6eaf964524ea"
      },
      "source": [
        "# modelo 1 de ANN\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "input_dim = 1     #  solo hay 1 feature\n",
        "model = torch.nn.Sequential(\n",
        "                torch.nn.Linear(input_dim, 40),   # 20 neuronas en primer layer\n",
        "                torch.nn.ReLU(),     # funcion de activacion\n",
        "                torch.nn.Linear(40, 20),   # segunda layer\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(20, 60),   # tercera layer\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(60, 20),   # cuarta layer\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(20, input_dim),   # quinta layer\n",
        "                )\n",
        "model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=40, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=40, out_features=20, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=20, out_features=60, bias=True)\n",
              "  (5): ReLU()\n",
              "  (6): Linear(in_features=60, out_features=20, bias=True)\n",
              "  (7): ReLU()\n",
              "  (8): Linear(in_features=20, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCtR441mQZHd"
      },
      "source": [
        "# optimizador y criterio de evaluacion.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.2)  # rata de aprendizaje lr.   # actualiza los pesos\n",
        "criteria = torch.nn.MSELoss() #  Ya que es un problema de regresion, usaré el criterio de error minimo cuadrado"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZK1Cn3gQZJB"
      },
      "source": [
        "# tranformo np arrays a tensores\n",
        "X_train_tensor = Variable(torch.from_numpy(X_train)).float()\n",
        "X_train_tensor = torch.unsqueeze(X_train_tensor,dim=1)\n",
        "X_test_tensor = Variable(torch.from_numpy(X_test)).float()\n",
        "Y_train_tensor = Variable(torch.from_numpy(Y_train)).float()\n",
        "Y_test_tensor  = Variable(torch.from_numpy(Y_test)).float()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJoRpjXDVAX7",
        "outputId": "b7c66070-43a3-4487-9608-0c813121d3c0"
      },
      "source": [
        "# entro mi ANN\n",
        "n_epoch = 50\n",
        "loss_list = []    # lista de errores por cada epoca\n",
        "accuracy_list = []\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  Y_pred = model(X_train_tensor)   # prediccion\n",
        "  loss = criteria(Y_pred, Y_train_tensor)   # calcula el error\n",
        "  loss_list.append(loss)\n",
        "\n",
        "  optimizer.zero_grad()   # borre los pesos anteriores\n",
        "  loss.backward()       # actualiza pesos con optimizadores de esta epoca\n",
        "  optimizer.step()     # aplique los pesos \n",
        "\n",
        "  correct = (torch.argmax(Y_pred, dim=1) == Y_train_tensor).type(torch.FloatTensor) # accuracy\n",
        "  accuracy_list.append(correct.mean())\n",
        "\n",
        "  print('Epoch [{}/{}], loss: {}, acc: {}'.format(epoch+1,n_epoch,loss_list[epoch],accuracy_list[epoch]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/50], loss: 0.6479961276054382, acc: 0.0\n",
            "Epoch [2/50], loss: 0.5358018279075623, acc: 0.0\n",
            "Epoch [3/50], loss: 0.5091615319252014, acc: 0.0\n",
            "Epoch [4/50], loss: 0.4994414150714874, acc: 0.0\n",
            "Epoch [5/50], loss: 0.4989071786403656, acc: 0.0\n",
            "Epoch [6/50], loss: 0.4985608458518982, acc: 0.0\n",
            "Epoch [7/50], loss: 0.4983142018318176, acc: 0.0\n",
            "Epoch [8/50], loss: 0.49813416600227356, acc: 0.0\n",
            "Epoch [9/50], loss: 0.4979999363422394, acc: 0.0\n",
            "Epoch [10/50], loss: 0.4978978931903839, acc: 0.0\n",
            "Epoch [11/50], loss: 0.4978187382221222, acc: 0.0\n",
            "Epoch [12/50], loss: 0.49775609374046326, acc: 0.0\n",
            "Epoch [13/50], loss: 0.49770569801330566, acc: 0.0\n",
            "Epoch [14/50], loss: 0.49766454100608826, acc: 0.0\n",
            "Epoch [15/50], loss: 0.4976305663585663, acc: 0.0\n",
            "Epoch [16/50], loss: 0.4976021349430084, acc: 0.0\n",
            "Epoch [17/50], loss: 0.4975781738758087, acc: 0.0\n",
            "Epoch [18/50], loss: 0.4975578188896179, acc: 0.0\n",
            "Epoch [19/50], loss: 0.49754032492637634, acc: 0.0\n",
            "Epoch [20/50], loss: 0.49752533435821533, acc: 0.0\n",
            "Epoch [21/50], loss: 0.4975123405456543, acc: 0.0\n",
            "Epoch [22/50], loss: 0.4975012242794037, acc: 0.0\n",
            "Epoch [23/50], loss: 0.4974914491176605, acc: 0.0\n",
            "Epoch [24/50], loss: 0.4974830448627472, acc: 0.0\n",
            "Epoch [25/50], loss: 0.49747562408447266, acc: 0.0\n",
            "Epoch [26/50], loss: 0.4974692463874817, acc: 0.0\n",
            "Epoch [27/50], loss: 0.497463583946228, acc: 0.0\n",
            "Epoch [28/50], loss: 0.4974586069583893, acc: 0.0\n",
            "Epoch [29/50], loss: 0.4974542558193207, acc: 0.0\n",
            "Epoch [30/50], loss: 0.49745044112205505, acc: 0.0\n",
            "Epoch [31/50], loss: 0.49744707345962524, acc: 0.0\n",
            "Epoch [32/50], loss: 0.4974440336227417, acc: 0.0\n",
            "Epoch [33/50], loss: 0.4974414110183716, acc: 0.0\n",
            "Epoch [34/50], loss: 0.49743902683258057, acc: 0.0\n",
            "Epoch [35/50], loss: 0.49743685126304626, acc: 0.0\n",
            "Epoch [36/50], loss: 0.49743491411209106, acc: 0.0\n",
            "Epoch [37/50], loss: 0.49743324518203735, acc: 0.0\n",
            "Epoch [38/50], loss: 0.49743160605430603, acc: 0.0\n",
            "Epoch [39/50], loss: 0.4974302351474762, acc: 0.0\n",
            "Epoch [40/50], loss: 0.49742889404296875, acc: 0.0\n",
            "Epoch [41/50], loss: 0.49742767214775085, acc: 0.0\n",
            "Epoch [42/50], loss: 0.4974265694618225, acc: 0.0\n",
            "Epoch [43/50], loss: 0.49742552638053894, acc: 0.0\n",
            "Epoch [44/50], loss: 0.4974246025085449, acc: 0.0\n",
            "Epoch [45/50], loss: 0.4974236786365509, acc: 0.0\n",
            "Epoch [46/50], loss: 0.49742284417152405, acc: 0.0\n",
            "Epoch [47/50], loss: 0.49742206931114197, acc: 0.0\n",
            "Epoch [48/50], loss: 0.4974212944507599, acc: 0.0\n",
            "Epoch [49/50], loss: 0.49742060899734497, acc: 0.0\n",
            "Epoch [50/50], loss: 0.49741992354393005, acc: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([400])) that is different to the input size (torch.Size([400, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrbispE1ZLAe"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmUDUh3JVAbq"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUfr7iq2VAd6"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NCRx_5gKsOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "26e3110e-4863-45a2-b6ff-d2e62cb57f71"
      },
      "source": [
        "\"\"\"Trate de diseñar al menos dos modelos diferentes \n",
        "(cambiando el número de capas y el número de neuronas) que le permitan obtener resultados óptimos \"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Trate de diseñar al menos dos modelos diferentes \\n(cambiando el número de capas y el número de neuronas) que le permitan obtener resultados óptimos '"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}